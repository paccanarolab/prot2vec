{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b363d52-0b30-4f28-a587-ca07c55714a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tools.datasets import SemanticSimilarityDataset\n",
    "from tools.utils import TrainingProgress\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e879bfee-ed3e-4ae4-a9d8-156e4527b049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a25ef3d21de4f41a7bec8ab17e343ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f43150014247b09a43c9c83c3422fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0474cba5694f61b7b1fc0f760ee1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss_bp_train = SemanticSimilarityDataset('../83333/train_data/')\n",
    "ss_bp_val = SemanticSimilarityDataset('../83333/val_data/')\n",
    "ss_bp_test = SemanticSimilarityDataset('../83333/test_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea17270-04d0-4318-a9b7-581ef2f14191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1855044\n",
      "validation 207025\n",
      "test 207025\n"
     ]
    }
   ],
   "source": [
    "for l, d in zip(['train', 'validation', 'test'], [ss_bp_train, ss_bp_val, ss_bp_test]):\n",
    "    print(l, len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c054f91-2a47-484a-babf-2e0bbe48e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(ss_bp_train, batch_size=256, num_workers=16)\n",
    "val_loader = DataLoader(ss_bp_val, batch_size=175, num_workers=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5998e16-2d1c-4cdb-8ed2-d8fabc7a8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0460b04-33ce-451e-a156-4de43e0727be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseSimilarityNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SiameseSimilarityNet, self).__init__()\n",
    "        self.prot2vec = nn.Sequential(\n",
    "            nn.Linear(7098, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, p1, p2):\n",
    "        p1 = self.prot2vec(p1)\n",
    "        p2 = self.prot2vec(p2)\n",
    "        batch_size = p1.shape[0]\n",
    "        dim = p1.shape[1]\n",
    "        return torch.bmm(p1.reshape(batch_size,1,dim), p2.reshape(batch_size,dim,1)).flatten()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd201bce-8766-4c92-8008-c0ed74e18e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseSimilarityNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc4687e-8c7a-4c2a-b573-84a14f0000c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model architecture:\n",
      "\n",
      " SiameseSimilarityNet(\n",
      "  (prot2vec): Sequential(\n",
      "    (0): Linear(in_features=7098, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "  )\n",
      ")\n",
      "\n",
      "The model has 7,995,392 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    temp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model architecture:\\n\\n', model)\n",
    "    print(f'\\nThe model has {temp:,} trainable parameters')\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60dce73d-05ed-478d-a643-7a23a044c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading checkpoint mechanisms\n",
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'val_loss': val_loss}\n",
    "\n",
    "    torch.save(state_dict, save_path)\n",
    "\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(model, optimizer):\n",
    "    save_path = f'siameseNet-batchnorm50.pt'\n",
    "    state_dict = torch.load(save_path)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    val_loss = state_dict['val_loss']\n",
    "    print(f'Model loaded from <== {save_path}')\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25379a6-7262-4ec7-9966-3d47c6e185bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c2177a8a534f98be898652eeadcb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50],Train Loss: 5.2281, Valid Loss: 4.60656838\n",
      "Model saved to ==> siameseNet-50_epochs.pt\n",
      "Epoch [2/50],Train Loss: 0.0334, Valid Loss: 0.35512739\n",
      "Model saved to ==> siameseNet-50_epochs.pt\n",
      "Epoch [3/50],Train Loss: 0.0333, Valid Loss: 0.04086203\n",
      "Model saved to ==> siameseNet-50_epochs.pt\n",
      "Epoch [4/50],Train Loss: 0.0222, Valid Loss: 0.16406885\n",
      "Epoch [5/50],Train Loss: 0.0195, Valid Loss: 0.02697304\n",
      "Epoch [6/50],Train Loss: 0.0164, Valid Loss: 0.02594845\n",
      "Model saved to ==> siameseNet-50_epochs.pt\n",
      "Epoch [7/50],Train Loss: 0.0161, Valid Loss: 0.02544737\n",
      "Model saved to ==> siameseNet-50_epochs.pt\n",
      "Epoch [8/50],Train Loss: 0.0161, Valid Loss: 0.02568234\n",
      "Epoch [9/50],Train Loss: 0.0161, Valid Loss: 0.02585709\n",
      "Epoch [10/50],Train Loss: 0.0161, Valid Loss: 0.02682058\n",
      "Epoch [11/50],Train Loss: 0.0161, Valid Loss: 0.02655192\n",
      "Epoch [12/50],Train Loss: 0.0161, Valid Loss: 0.02506588\n",
      "Model saved to ==> siameseNet-50_epochs.pt\n",
      "Epoch [13/50],Train Loss: 0.0160, Valid Loss: 0.02354558\n",
      "Model saved to ==> siameseNet-50_epochs.pt\n",
      "Epoch [14/50],Train Loss: 0.0161, Valid Loss: 0.02402114\n",
      "Epoch [15/50],Train Loss: 0.0160, Valid Loss: 0.02326404\n",
      "Epoch [16/50],Train Loss: 0.0161, Valid Loss: 0.02391978\n",
      "Epoch [17/50],Train Loss: 0.0160, Valid Loss: 0.02427889\n",
      "Epoch [18/50],Train Loss: 0.0160, Valid Loss: 0.02324401\n",
      "Model saved to ==> siameseNet-50_epochs.pt\n",
      "Epoch [19/50],Train Loss: 0.0160, Valid Loss: 0.02349923\n",
      "Epoch [20/50],Train Loss: 0.0161, Valid Loss: 0.02436656\n",
      "Epoch [21/50],Train Loss: 0.0160, Valid Loss: 0.02404499\n",
      "Epoch [22/50],Train Loss: 0.0160, Valid Loss: 0.02470128\n",
      "Epoch [23/50],Train Loss: 0.0160, Valid Loss: 0.02491030\n",
      "Epoch [24/50],Train Loss: 0.0160, Valid Loss: 0.02584352\n",
      "Epoch [25/50],Train Loss: 0.0160, Valid Loss: 0.02598943\n",
      "Epoch [26/50],Train Loss: 0.0160, Valid Loss: 0.02698720\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.0006)\n",
    "num_epochs = 50\n",
    "criterion = nn.MSELoss()\n",
    "save_name = f'siameseNet-{num_epochs}_epochs.pt'\n",
    "\n",
    "best_val_loss = float(\"Inf\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "cur_step = 0\n",
    "\n",
    "with TrainingProgress() as progress:\n",
    "    epochs = progress.add_task(\"[green]Epochs\", progress_type=\"epochs\", total=num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        training = progress.add_task(f\"[magenta]Training [{epoch}]\", total=len(train_loader), progress_type=\"training\")\n",
    "        validation = progress.add_task(f\"[cyan]Validation [{epoch}]\", total=len(val_loader), progress_type=\"validation\")\n",
    "        \n",
    "        for p1, p2, sim in train_loader:\n",
    "            # forward\n",
    "            p1 = p1.to(device)\n",
    "            p2 = p2.to(device)\n",
    "            sim = sim.to(device)\n",
    "            outputs = model(p1, p2)\n",
    "            loss = criterion(outputs, sim)\n",
    "\n",
    "            #backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            progress.advance(training)\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "    \n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for p1, p2, sim in val_loader:\n",
    "                p1 = p1.to(device)\n",
    "                p2 = p2.to(device)\n",
    "                sim = sim.to(device)\n",
    "                outputs = model(p1, p2)\n",
    "                loss = criterion(outputs, sim)\n",
    "                val_running_loss += loss.item()\n",
    "                progress.advance(validation)\n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}'\n",
    "              .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
    "        \n",
    "        # progress.tasks[training].visible = False\n",
    "        # progress.tasks[validation].visible = False\n",
    "        progress.advance(epochs)\n",
    "                \n",
    "print(\"Finished Training\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09c31b3b-ad17-48c5-94ed-80fba1459218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting of training and validation loss\n",
    "fix, axs = plt.subplots(nrows=2, figsize=(10,10), facecolor='white')\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.grid(ls=':', zorder=1)\n",
    "    if i != 0:\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylabel('Loss (log scale)')\n",
    "    ax.plot(train_losses, label='Train Loss')\n",
    "    ax.plot(val_losses, label=\"Validation Loss\")\n",
    "    ax.legend(loc='upper right')\n",
    "plt.savefig('E:/prot2vec/loss-evol.png')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463bbf61-2d7c-44c6-a873-8c4d3c9a6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.prot2vec(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2228ff6-6080-4b27-b42f-bf6de2c07e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a1b60-f8e8-4c30-9bc8-8284c1b056fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {'protein':[], 'prot2vec':[]}\n",
    "for accession, interpro in track(ss_bp_train.interpro_dict.items(), description='Training set'):\n",
    "    ip = torch.from_numpy(interpro.astype(np.float32)).to(device)\n",
    "    x = model.prot2vec(ip)\n",
    "    embeddings['protein'].append(accession)\n",
    "    embeddings['prot2vec'].append(x.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "for accession, interpro in track(ss_bp_val.interpro_dict.items(), description='Validation set'):\n",
    "    ip = torch.from_numpy(interpro.astype(np.float32)).to(device)\n",
    "    x = model.prot2vec(ip)\n",
    "    embeddings['protein'].append(accession)\n",
    "    embeddings['prot2vec'].append(x.cpu().detach().numpy())\n",
    "\n",
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8883c-e6dd-473b-be35-9d9954aca4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131b50f-465c-4dc5-9047-cc1f6bd8f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.from_numpy(a)\n",
    "B = torch.from_numpy(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc7fc5-8f90-40c8-be68-1a369c4dbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cf6be-9d4f-44fc-ae5c-4efdf5a805a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bmm(A.reshape(2,1,3), B.reshape(2,3,1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e2673-f6f4-4a61-9514-8b07516df770",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.reshape(2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd62040-3e73-42f4-b962-5ec682a36881",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(1.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92918bc0-de24-4eda-8f6d-f57ab14483aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cfaee8-b95a-431b-8371-948403ec15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_bp_train.ss_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf09a17-03f6-4af6-892a-b636ad3600b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
